#================Crawler Config================
#项目名称
crawler.project_name=hudong

#URL种子，中间以;分开
crawler.URL_seeds=http://www.hudong.com;

#爬行网站选择：0――自定义；1――百度百科；2――互动百科；3――新浪新闻；4――搜狐新闻；
crawler.website=2

#若上面项选择为0，请输入网址过滤规则
#分析网址形式
crawler.accepted_patterns=
#下载网址形式
crawler.download_patterns=
#拒绝网址形式
crawler.rejected_patterns=
#主机地址
crawler.host=null

#网页来源
crawler.comefrom=

#作者信息所在tag
crawler.author.tag=span 
crawler.author.attribute=nslog:1022

#更新时间信息所在 tag
crawler.modifyTime.tag=span
crawler.modifyTime.attribute=lastModifyTime

#下载选项：
#是否下载原始HTML，是--1，否--0；
crawler.origin_html=0
crawler.downloadImage=0

#是否对预料进行预处理，是--1，否--0；
crawler.parse_text=1

#最大线程数
crawler.max_thread_quantity=120

#数据编码
crawler.charset=UTF-8

#网页抓取间隔(毫秒)
crawler.politeness_delay=500

#日志目录
crawler.log_home=log

#数据存放位置
crawler.data.home=data/fetchedPage



#失败重试次数
crawler.retry_times=3

#=================HTTP连接配置====================


#连接超时(单位：毫秒)
connection.timeout=6000


#================Database Config===========
#数据库从内存写入磁盘间隔（分钟，防止数据丢失）
database.flush_interval=5

#数据存放路径
database.home=data/database

